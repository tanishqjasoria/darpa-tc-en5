input {
	log4j {
		host => "0.0.0.0"
		port => 4712 
#		codec => "json"
		mode => "server"
	}	

#	kafka {
#		bootstrap_servers => "128.55.12.59:9092"
#		topics => ["ta1-trace-1-e5-bgt-1"]
##		topics => ["ta1-fivedirections-1-e5-bgt-1"]
#		auto_offset_reset => "earliest"
#		key_deserializer_class => "org.apache.kafka.common.serialization.ByteArrayDeserializer"
#		value_deserializer_class => "org.apache.kafka.common.serialization.ByteArrayDeserializer"
##		key_deserializer_class => "com.bbn.tc.schema.serialization.kafka.KafkaAvroGenericDeserializer"
##		value_deserializer_class => "com.bbn.tc.schema.serialization.kafka.KafkaAvroGenericDeserializer"
#		group_id => "480bb378-4568-46af-bece-80257b0701e9"
##		group_id => "logstash"
#		codec => avro {
#			schema_uri => "/tmp/schema.avsc"
#		}
#	}
#	tcp {
#		port => 5000
#	}
}

## Add your filters / logstash plugins configuration here
filter {
    json {
        source => "message"
        target => "message"
    }

# Following is not needed. Above does all parsing properly
#    json {
#        source => "[message][datum]"
#        target => "[message][datum]"
#    }
#
#    mutate {
#        add_field => { "TEST_FIELD_123" => "ABC123" }
#    }
#
#    mutate {
#        add_field => { "[message][datum][com.bbn.tc.schema.avro.cdm20.Event][TEST_FIELD_ABC]" => "DEF456" }
#    }
#    
#    mutate {
#        add_field => { "[message][datum][TEST_FIELD_IJK]" => "GHI789" }
#    }
#    mutate {
#        add_field => { "[message][TEST_FIELD_XYZ]" => "JWQEFW" }
#    }
#
#
#   **** THIS IS THE ONE THAT SHOULD BE AT THE RIGHT LEVEL! ****
#    mutate {
#        add_field => { "[datum][TEST_FIELD_QWE]" => "REHEFW" }
#    }
#
#
#
#    
#  Added back because I was gettng
# logstash_1       | [2019-09-12T22:22:53,811][DEBUG][logstash.filters.mutate  ] gsub mutation is only applicable for strings and arrays of strings, skipping {:field=>"[datum][timestampNanos]", :value=>nil}

    mutate {
        convert => {
            "[message][datum][com.bbn.tc.schema.avro.cdm20.Event][timestampNanos]" => "string"
        }
    }

    mutate {
        gsub => ["[message][datum][com.bbn.tc.schema.avro.cdm20.Event][timestampNanos]", "\d{6}$", ""]
    }

    date {
        match => ["[message][datum][com.bbn.tc.schema.avro.cdm20.Event][timestampNanos]", "UNIX_MS"]
        timezone => "UTC"
        locale => "en"  
#	target => "TEST_FIELD"
        target => "@timestamp"
    }

    mutate {
        convert => {
            "[datum][timestampNanos]" => "string"
        }
    }
    mutate {
        gsub => ["[datum][timestampNanos]", "\d{6}$", ""]
    }

    date {
        match => ["[datum][timestampNanos]", "UNIX_MS"]
        timezone => "America/New_York"
        locale => "en"  
        target => "@timestamp"
    }
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
	}
	stdout { codec => rubydebug }
}
